# 🕵️ AI Mafia — LLM 기반 심리전 마피아 게임  
> Runpod + Ollama(EEVE-Korean-10.8B) 기반 • 자연스러운 사회적 상호작용 실험

---

## 📌 프로젝트 개요
AI 기반의 마피아 게임을 텍스트로 플레이하는 프로젝트입니다.  
🧠 **플레이어 1명 + AI 6명**  
LLM이 각각의 캐릭터처럼 행동하며, **심리전 중심의 토론 → 투표 → 밤 연출** 흐름으로 진행됩니다.

원래는  
> 경찰, 의사, 사냥꾼, 차단자 등의 능력까지 구현해  
> **상태 기반 추론 + 행동 결과 반영 + 맥락 대화**  
을 노렸으나,  
LLM 기반 대화의 현실적 한계를 고려해  
**“능력 없는 심리전 중심 모델”** 로 피벗했습니다.

---

## 🎮 최종 플레이 목표
- 플레이어는 **AI들과 토론하며 마피아를 찾아 투표**
- AI는 자연스러운 감정·심리 묘사
- 실제 마피아 게임처럼  
  - 조용한 사람 의심  
  - 주장을 뒷받침  
  - 반박 / 행동 묘사  
가 드러나도록 설계

---

## 🧱 시스템 구성
```
Runpod GPU Container
│
├── Ollama (EEVE-Korean-10.8B 모델)
│ └─ /api/chat 로 JSON 호출
│
└── Python Game Engine
├── mafia_core.py # 게임 상태 & 라운드 관리
├── prompts.py # 프롬프트 설계
├── llm_engine.py # Ollama API 호출
├── main.py # 터미널 플레이
└── README.md
```


---

## 🤖 기술 스택
```
| 기술 | 목적 |
|------|------|
| Runpod | GPU 호스팅 |
| Ollama | 로컬 LLM 실행 서버 |
| EEVE Korean 10.8B | AI 역할/대사 생성 |
| Python | 게임 엔진 |
| JSON I/O | 상태·행동 명시적 전달 |
```
---

## ⚙️ 실행 흐름

밤 연출

낮 토론

플레이어 발언

AI 반응

투표

승패 체크 → 다음 라운드


### 낮 토론
- 플레이어 한 줄 발언
- AI가 3~5명 발언/묘사
- 조용한 AI → 행동 묘사(…) 로 표현

### 투표
- AI + 플레이어가 지목
- 최다 득표자 사망

---

## 🤔 도전 과제 & 해결

### ✅ 1) LLM이 JSON을 정확히 생성하지 않음
- EEVE는 구조화 응답(JSON)에 취약
- → `SYSTEM_PROMPT`에서  
  **"오직 JSON만"** 강하게 요구
- 후처리로 파싱 실패 시 재시도

---

### ✅ 2) 능력을 반영한 자연스러운 대화가 거의 불가능
원래 구현하려던 구조:

> 밤 능력 → 결과 반영  
→ 다음날 대화에서  
"경찰이 민수 조사해 시민이래"  
"의사가 누구 치료했대"  
이런 방식의 **상태 기반 추론**을 기대했지만…

LLM은
- 기억력 약함
- 상태 기반 reasoning 부족
- Plot continuity 구현 어려움  
이라는 구조적 한계 →  
결국 AI의 대사는  
**상황과 무관한 일반 채팅**이 반복됨

✅ 해결  
→ **능력 제거 / 순수 심리전 중심 게임** 로 전환

---

### ✅ 3) 대사가 계속 비슷해짐 → fallback 제어
- 묘사 중심
- “일단 더 보고 판단하겠습니다” 반복
- 마피아 게임 같지 않음

→ 해결
- fallback을 **다양한 행동묘사**로 변환  

예:
(눈을 피한다.)
(긴장을 숨기지 못한다.)
(입술을 깨문다.)
(주위를 살핀다.)



---

### ✅ 4) 잡담, 일상대화, 농담 발생
> "하하 같이 수다 떨자"  
> "마을에 충성해주세요"  
처럼,  
마피아 토론과 무관한 대사가 다수 발생

→ 해결
- 금지 규칙 추가
  - 인사, 주제 제안, 농담, 친목, 협력, 충성 금지
- 필터링 후  
  → 짧은 추리/반박으로 정규화

---

### ✅ 5) 너무 조용해지는 문제
→ “**최소 2인 이상은 반드시 발언**” 규칙 추가  
→ 모두 묘사만 발생 시  
  → 2명은 발언으로 강제 변환  
(“계속 침묵하네요. 더 수상합니다.”)

---

## 📈 무엇을 배웠나

### ✅ LLM은 능력 + 상태 기반 추론이 어렵다
- “경찰이 X 조사→ 시민” → 기억  
- 다음날 토론에 반영  
이런 흐름은  
**메모리 저장·요약·재삽입** 없이 불가능

---

### ✅ 심리전만으로도 재미 만들 수 있다
- 말 줄임
- 묘사
- 의심/반박
- 반응 패턴
만으로도 꽤 자연스러운 마피아 분위기 가능

---

### ✅ Prompt engineering + 후처리가 핵심
- Output schema 강제
- 금지 패턴 필터
- fallback 묘사
- 최소 발언 보장

> **LLM 성능보다 prompt + 룰엔진 설계가 더 중요했다**

---

## 🧪 시연 예시

당신: 민수 뭐했어
민수: 지연이 너무 조용해서 수상해요.
수아: 저는 시민입니다. 억울해요.
하린: (눈을 피한다.)
태훈: 계속 말이 없네요. 뭔가 숨기는 듯합니다.

yaml
코드 복사

---

## 🔚 결론

LLM(EEVE) 기반 마피아 게임은  
**행동 능력(경찰/의사…)을 기준으로 추론을 전개하는 구조는 매우 어렵지만,  
순수 대화 심리전 모델로는 재미 요소가 충분했다.**

따라서  
- 기능적 → 능력 없는 심리전 스타일  
- 기술적 → Prompt + 후처리 기반

이라는 방향이  
가장 현실적이고 자연스러운 결과를 만들어냈다.

---

## 🚦 차후 개선
- 더 강한 reasoning 모델 적용 (GPT-5 / QwQ 등)
- Memory 기반 상태 요약 → 다음 prompt 삽입
- 캐릭터별 성향(personality) 부여
- Streamlit UI
- 멀티턴 저장/불러오기

---

## 📁 파일 구조
```
.
├── main.py # 터미널 실행
├── mafia_core.py # 게임 룰 & 상태
├── prompts.py # 프롬프트
├── llm_engine.py # Ollama 호출
└── README.md
```
